{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from catboost import CatBoostRegressor \n",
    "\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/df_train_sinmodelosunicos.csv\") \n",
    "df_test = pd.read_csv(\"./data/df_test_prueba_larga.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor MAE de RandomForestRegressor: 156.25645315565728\n",
      "Mejores hiperparámetros de RandomForestRegressor: {'n_estimators': 139}\n",
      "Mejor MAE de XGBoost: 150.33629984422166\n",
      "Mejores hiperparámetros de XGBoost: {'n_estimators': 124, 'learning_rate': 0.12}\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop(columns=['Price_euros'])\n",
    "y = df_train['Price_euros']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocesamiento para columnas numéricas\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocesamiento para columnas categóricas\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Crear el ColumnTransformer para aplicar el preprocesamiento adecuado a cada columna\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "# Definir diferentes combinaciones de hiperparámetros para probar en RandomForestRegressor\n",
    "hyperparameters = [{'n_estimators': 139}]\n",
    "best_mae = float('inf')\n",
    "best_model = None\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Probar diferentes combinaciones de hiperparámetros en RandomForestRegressor\n",
    "for params in hyperparameters:\n",
    "    # Crear el pipeline completo con el nuevo hiperparámetro\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(**params, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Guardar el mejor modelo y sus hiperparámetros\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_model = pipeline\n",
    "        best_hyperparameters = params\n",
    "\n",
    "# Definir diferentes combinaciones de hiperparámetros para probar en XGBoost\n",
    "xgb_hyperparameters = [\n",
    "                    \n",
    "                        {'n_estimators': 123, 'learning_rate': 0.12},\n",
    "                        {'n_estimators': 124, 'learning_rate': 0.12}, \n",
    "                        {'n_estimators': 125, 'learning_rate': 0.12}\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "                       ]\n",
    "\n",
    "# Mejor MAE y modelo para XGBoost\n",
    "best_xgb_mae = float('inf')\n",
    "best_xgb_model = None\n",
    "best_xgb_hyperparameters = None\n",
    "\n",
    "# Probar diferentes combinaciones de hiperparámetros en XGBoost\n",
    "for xgb_params in xgb_hyperparameters:\n",
    "    # Crear el pipeline completo con el nuevo hiperparámetro\n",
    "    xgb_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', XGBRegressor(**xgb_params, random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo en el conjunto de prueba\n",
    "    y_xgb_pred = xgb_pipeline.predict(X_test)\n",
    "    xgb_mae = mean_absolute_error(y_test, y_xgb_pred)\n",
    "\n",
    "    # Guardar el mejor modelo y sus hiperparámetros\n",
    "    if xgb_mae < best_xgb_mae:\n",
    "        best_xgb_mae = xgb_mae\n",
    "        best_xgb_model = xgb_pipeline\n",
    "        best_xgb_hyperparameters = xgb_params\n",
    "\n",
    "# Imprimir el MAE más bajo y los hiperparámetros correspondientes de RandomForestRegressor\n",
    "print(\"Mejor MAE de RandomForestRegressor:\", best_mae)\n",
    "print(\"Mejores hiperparámetros de RandomForestRegressor:\", best_hyperparameters)\n",
    "\n",
    "# Imprimir el MAE más bajo y los hiperparámetros correspondientes de XGBoost\n",
    "print(\"Mejor MAE de XGBoost:\", best_xgb_mae)\n",
    "print(\"Mejores hiperparámetros de XGBoost:\", best_xgb_hyperparameters)\n",
    "\n",
    "# Si el mejor modelo es XGBoost, usarlo para predecir los precios en el conjunto de prueba\n",
    "if best_xgb_mae < best_mae:\n",
    "    predicciones = best_xgb_model.predict(df_test)\n",
    "else:\n",
    "    predicciones = best_model.predict(df_test)\n",
    "\n",
    "# Añadir las predicciones al dataframe de prueba\n",
    "df_test['Price_euros'] = predicciones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflimpio = pd.DataFrame()\n",
    "dflimpio['id'] = df_test['id']\n",
    "dflimpio['Price_euros'] = df_test['Price_euros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflimpio.to_csv('precios/df_test_largooo      l .csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
